{
  "authors": [
    "Brian Barrett",
    "Brendan Koerner",
    "Angela Watercutter",
    "Arielle Pardes",
    "Wired Staff",
    "Josie Colt",
    "Jeffrey Van Camp",
    "Garrett M. Graff"
  ],
  "date_download": "2018-02-06T16:58:35",
  "date_modify": null,
  "date_publish": "2018-02-05T17:00:53",
  "description": "After months of lurking unused in Google's flagship Pixel 2 smartphone, the company's first homegrown, consumer-focused processor springs to life.",
  "filename": "https%3A%2F%2Fwww.wired.com%2Fstory%2Fgoogle-pixel-visual-core%2F.json",
  "image_url": "https://media.wired.com/photos/5a786d987727381295d0917f/191:100/pass/GettyImages-857598816.jpg",
  "language": null,
  "localpath": null,
  "source_domain": "www.wired.com",
  "text": "When Google launched its Pixel 2 flagship smartphone last year, it included something of a surprise: A co-processor called Pixel Visual Core, the company\u2019s first homegrown, consumer-facing piece of silicon. And while that feels like a momentous foray, the co-processor has lain dormant for months. Monday, Pixel Visual Core goes to work.\nAs it turns out\u2014and as Google had nodded at previously\u2014the hidden chip inside every Pixel serves a narrow but critical purpose. It will use its eight custom cores, its ability to crunch 3 trillion operations per second, all in the service of making your photos look better. Specifically, the photos you take through third-party apps like Instagram, WhatsApp, and Snapchat.\nThose are the three partners at the Pixel Visual Core switch-flipping; since it\u2019s open to all developers, more will presumably follow. They\u2019ll all gain the powers to produce Google's HDR+ images, photos that rely on a series of post-processing tricks to make images shot with the Pixel appear more balanced and lifelike. Photos taken with the Pixel Camera app have already benefited from HDR+ powers since launch\u2014that's one reason Pixel 2 earned the highest marks yet given to a smartphone by industry-standard photo-rater DxOMark. But Pixel Visual Core will extend the feature to the streams, feeds, and snaps of Pixel owners as well, after an update that will roll out early this week.\nHDR+\nTo understand why Google would devote its first homemade smartphone processor to a relatively narrow function\u2014not just photography, but HDR+ specifically\u2014it helps to understand the importance of HDR+ to the Pixel\u2019s photo prowess. For starters, it\u2019s not the HDR you\u2019re used to.\n\u201cHDR+ actually works shockingly differently,\u201d says Isaac Reynolds, project manager for Pixel Camera. Where HDR essentially tries to combine three or so simultaneous exposures for the best result, HDR+ takes up to 10 identical underexposed shots. \u201cWe take them all and chop them into little bits, and line them on top of one another, and average the image together,\u201d says Reynolds, who ticks off the reduction in noise and color quality as just two of the benefits.\nThat\u2019s not just hype, or at least not entirely. HDR+ really does have tangible benefits\u2014especially in Google\u2019s implementation.\n\u201cHDR+ technology is a very good technology for noise and data preservation. This removes the noise in the picture,\u201d says Herv\u00e9 Macudzinski, manager of DxOMark.com. \u201cThat enables Google to provide a nice picture with low level noise high level detail.\u201d\nYou can see an example of what that means in the below before-and-after shots, with the usual caveat that Google provided them, and your own experience may vary.\nThe various benefits of HDR+ are also more or less pronounced depending on the conditions of the shot you\u2019re taking. It helps especially bringing clarity to low-light images, or to give an assist if you for some reason take a portrait with the sun at someone\u2019s back.\nGoogle\u2019s not the only company capable of this particular trick, but its execution clearly stands apart.\n\u201cThe HDR+ is very impressive because they did something very efficient,\u201d says Macudzinski. \u201cIf you want to do that, it\u2019s going to be optimized and very powerful.\u201d\nPixel Visual Core will also power two related photographic enhancements; RAISR, a technique to sharpen zoomed-in shots, and Zero Shutter Lag, which is exactly what it sounds like.\nUntil now, these optimizations have been off limits for third-party developers. Photos taken within the Instagram app, for instance, look a bit muddled compared to those taken with the Pixel\u2019s native camera app. Which is where Pixel Visual Core comes in.\nSharing the Wealth\nThe primary benefit of the Pixel Visual Core, now that it\u2019s on? You still won\u2019t even notice it, says Ofer Shacham, the chip\u2019s engineering manager.\n\u201cIf we look at HDR+ as a key benchmark for us, it gives us the ability to run five times faster than anything else in existence, while consuming about 1/10th of the energy of the battery. We can put it under the hood,\u201d says Schacham. \u201cWe basically hide it. That\u2019s what enables every developer to use it, while not consuming energy from the battery, and even better, reducing the energy consumption from the battery while those applications take pictures.\u201d\nThat also hints at why Google decided to go it alone with Pixel Visual Core, rather than rely on the powerful Snapdragon 835 processor that handles the bulk of the Pixel 2\u2019s computational needs. The Pixel Visual Core offers not just customization, but flexibility.\n\u201cGoogle in a sense is a software and algorithm company,\u201d says Schacham. \u201cWe want something that allows us to rapidly innovate, rapidly change the algorithm, rapidly improve it.\u201d\nTo that end, the Pixel Visual Core is also programmable. That means while it works primarily in service of HDR+ today, it could go toward making other applications zip in the future, a possibility that Schacham acknowledges, while declining to go into detail on what sorts of use cases Google envisions.\nMore broadly, though, the Pixel Visual Core represents Google\u2019s first foray into an increasingly common trend of smartphone manufacturers rolling their own silicon, giving itself tighter control over its product and weaning itself off of chip giant Qualcomm.\nThe Pixel Visual Core represents Google\u2019s first foray into an increasingly common trend of smartphone manufacturers rolling their own silicon.\n\u201cI think it\u2019s significant in that, first off, Google is an advertising company, who is also an operating system provider, and they are going more deeply vertical in what they\u2019re doing by adding semiconductor features to enhance the experience,\u201d says Patrick Moorhead, president of Moor Insights & Strategies. \u201cAny time somebody in software gets into hardware, interesting things happen\u2014as in interesting really good, or interesting really bad.\u201d\nIt would also make sense, Moorhead says, for Google to extend its processor plans beyond Pixel Visual Core. Microsoft uses a custom system-on-a-chip for the Xbox. Apple\u2019s A series SoC has contributed greatly to the iPhone\u2019s dominance. And with Google having poached a key Apple chip designer last summer, it seems unlikely that an HDR+ coprocessor is the end of the line.\nFor now, though, Pixel 2 owners can look forward to adding an HDR+ veneer to their social media pics\u2014while waiting Google\u2019s broader ambitions to come more fully into focus.\nPixel Perfect",
  "title": "Pixel Visual Core Now Adds HDR+ To Instagram, WhatsApp, and Snapchat Images",
  "title_page": null,
  "title_rss": null,
  "url": "https://www.wired.com/story/google-pixel-visual-core/",
  "dId": "3a4da57f7b53d48b94b8fe7f096dee9348003d68f8874865e5a2b55a",
  "newsCluster": {
    "CategoryId": 3,
    "Category": "technology",
    "TopicId": 1,
    "Topic": "unspecific",
    "EventId": 58,
    "Event": "Google_enables_Pixel_Visual_Core"
  }
}